{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stu_etl_s3_rds.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y6pz7LGh_L1p",
        "colab": {}
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cmi3lW_-dMl",
        "colab_type": "code",
        "outputId": "039923b4-3336-4801-e49a-178cffd36db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-10 14:59:52--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar.2’\n",
            "\n",
            "\rpostgresql-42.2.9.j   0%[                    ]       0  --.-KB/s               \rpostgresql-42.2.9.j 100%[===================>] 892.61K  4.67MB/s    in 0.2s    \n",
            "\n",
            "2020-04-10 14:59:52 (4.67 MB/s) - ‘postgresql-42.2.9.jar.2’ saved [914037/914037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mDb47oN-dMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CoronaETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aIGU4Tzs_Q4g",
        "outputId": "18d9d928-8275-4cbd-a083-a7b9ceba59ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from pyspark import SparkFiles\n",
        "# Load in employee.csv from S3 into a DataFrame\n",
        "url = \"https://project-pandemix.s3.us-east-2.amazonaws.com/COVID-10+Cases+v2.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "corona_df = spark.read.option('header', 'true').csv(SparkFiles.get(\"COVID-10+Cases+v2.csv\"), inferSchema=True, sep=',', timestampFormat=\"mm/dd/yy\")\n",
        "corona_df.show(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+--------------------+------+---------+------+\n",
            "|               Date|            Country|               State|County|Confirmed|Deaths|\n",
            "+-------------------+-------------------+--------------------+------+---------+------+\n",
            "|2020-01-22 00:01:00|        Afghanistan|                None|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|            Albania|                None|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|            Algeria|                None|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|            Andorra|                None|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|             Angola|                None|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|Antigua and Barbuda|                None|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|          Argentina|                None|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|            Armenia|                None|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|          Australia|Australian Capita...|  None|        0|     0|\n",
            "|2020-01-22 00:01:00|          Australia|     New South Wales|  None|        0|     0|\n",
            "+-------------------+-------------------+--------------------+------+---------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l9SAmpciShq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.types import DateType"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO6NUJjFCybk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corona_df1=corona_df.withColumn(\"Date_1\",corona_df['Date'].cast(DateType()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnTu_OXzinH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corona_new_df=corona_df1.select(\"Date_1\",\"Country\",\"State\",\"County\",\"Confirmed\",\"Deaths\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "10qoqQv3_Y_w",
        "outputId": "0aad1a44-7a9b-4991-9386-963f5dc959c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "corona_new_df.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------------+--------------------+------+---------+------+\n",
            "|    Date_1|            Country|               State|County|Confirmed|Deaths|\n",
            "+----------+-------------------+--------------------+------+---------+------+\n",
            "|2020-01-22|        Afghanistan|                None|  None|        0|     0|\n",
            "|2020-01-22|            Albania|                None|  None|        0|     0|\n",
            "|2020-01-22|            Algeria|                None|  None|        0|     0|\n",
            "|2020-01-22|            Andorra|                None|  None|        0|     0|\n",
            "|2020-01-22|             Angola|                None|  None|        0|     0|\n",
            "|2020-01-22|Antigua and Barbuda|                None|  None|        0|     0|\n",
            "|2020-01-22|          Argentina|                None|  None|        0|     0|\n",
            "|2020-01-22|            Armenia|                None|  None|        0|     0|\n",
            "|2020-01-22|          Australia|Australian Capita...|  None|        0|     0|\n",
            "|2020-01-22|          Australia|     New South Wales|  None|        0|     0|\n",
            "|2020-01-22|          Australia|  Northern Territory|  None|        0|     0|\n",
            "|2020-01-22|          Australia|          Queensland|  None|        0|     0|\n",
            "|2020-01-22|          Australia|     South Australia|  None|        0|     0|\n",
            "|2020-01-22|          Australia|            Tasmania|  None|        0|     0|\n",
            "|2020-01-22|          Australia|            Victoria|  None|        0|     0|\n",
            "|2020-01-22|          Australia|   Western Australia|  None|        0|     0|\n",
            "|2020-01-22|            Austria|                None|  None|        0|     0|\n",
            "|2020-01-22|         Azerbaijan|                None|  None|        0|     0|\n",
            "|2020-01-22|            Bahamas|                None|  None|        0|     0|\n",
            "|2020-01-22|            Bahrain|                None|  None|        0|     0|\n",
            "+----------+-------------------+--------------------+------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "klopnaUE_eZV"
      },
      "source": [
        "## Rename columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXwKMfOsDGvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def renameCols(df, old_columns, new_columns):\n",
        "    for old_col,new_col in zip(old_columns,new_columns):\n",
        "        df = df.withColumnRenamed(old_col,new_col)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ftlVc26DJX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_columns = ['Date_1','Country',\"State\",\"County\",\"Confirmed\",\"Deaths\"]\n",
        "new_columns = [\"date\", \"country\",\"state\",\"county\",\"confirmed\",\"deaths\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGSpZ8-JDszi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corona_conv_df = renameCols(corona_new_df, old_columns, new_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCg5ttyYCVRO",
        "colab_type": "code",
        "outputId": "088767de-b417-4fba-d87a-8fd66d8a4cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "corona_conv_df.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------------+--------------------+------+---------+------+\n",
            "|      date|            country|               state|county|confirmed|deaths|\n",
            "+----------+-------------------+--------------------+------+---------+------+\n",
            "|2020-01-22|        Afghanistan|                None|  None|        0|     0|\n",
            "|2020-01-22|            Albania|                None|  None|        0|     0|\n",
            "|2020-01-22|            Algeria|                None|  None|        0|     0|\n",
            "|2020-01-22|            Andorra|                None|  None|        0|     0|\n",
            "|2020-01-22|             Angola|                None|  None|        0|     0|\n",
            "|2020-01-22|Antigua and Barbuda|                None|  None|        0|     0|\n",
            "|2020-01-22|          Argentina|                None|  None|        0|     0|\n",
            "|2020-01-22|            Armenia|                None|  None|        0|     0|\n",
            "|2020-01-22|          Australia|Australian Capita...|  None|        0|     0|\n",
            "|2020-01-22|          Australia|     New South Wales|  None|        0|     0|\n",
            "|2020-01-22|          Australia|  Northern Territory|  None|        0|     0|\n",
            "|2020-01-22|          Australia|          Queensland|  None|        0|     0|\n",
            "|2020-01-22|          Australia|     South Australia|  None|        0|     0|\n",
            "|2020-01-22|          Australia|            Tasmania|  None|        0|     0|\n",
            "|2020-01-22|          Australia|            Victoria|  None|        0|     0|\n",
            "|2020-01-22|          Australia|   Western Australia|  None|        0|     0|\n",
            "|2020-01-22|            Austria|                None|  None|        0|     0|\n",
            "|2020-01-22|         Azerbaijan|                None|  None|        0|     0|\n",
            "|2020-01-22|            Bahamas|                None|  None|        0|     0|\n",
            "|2020-01-22|            Bahrain|                None|  None|        0|     0|\n",
            "+----------+-------------------+--------------------+------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0PDvBiVN_jGe"
      },
      "source": [
        "## Write DataFrame to RDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fOIS3viE_leJ",
        "colab": {}
      },
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"overwrite\"\n",
        "jdbc_url=\"jdbc:postgresql://corona.cuo7ivhfh3jn.us-east-1.rds.amazonaws.com:5432/corona\"\n",
        "config = {\"user\":\"root\", \n",
        "          \"password\": \"postgress\", \n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K6_O84CK_nV5",
        "colab": {}
      },
      "source": [
        "corona_conv_df.write.jdbc(url=jdbc_url, table='corona_db', mode=mode, properties=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tvw--Ool_vju",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}